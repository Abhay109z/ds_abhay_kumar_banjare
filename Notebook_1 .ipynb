{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pGwI9GYdGoT5",
        "outputId": "0a7f3962-ad33-4284-d579-4fde6222eed6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Folders created:\n",
            "ds_abhay_kumar_banjare\n",
            "ds_abhay_kumar_banjare/csv_files\n",
            "ds_abhay_kumar_banjare/outputs\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "ROOT = \"ds_abhay_kumar_banjare\"\n",
        "CSV = f\"{ROOT}/csv_files\"\n",
        "OUT = f\"{ROOT}/outputs\"\n",
        "\n",
        "for d in [ROOT, CSV, OUT]:\n",
        "    os.makedirs(d, exist_ok=True)\n",
        "\n",
        "print(\"Folders created:\")\n",
        "print(ROOT)\n",
        "print(CSV)\n",
        "print(OUT)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "096ebb3a",
        "outputId": "8ed35b2f-5595-4d9d-c579-a0dab7f21d9a"
      },
      "source": [
        "pip install reportlab"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting reportlab\n",
            "  Downloading reportlab-4.4.5-py3-none-any.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: pillow>=9.0.0 in /usr/local/lib/python3.12/dist-packages (from reportlab) (11.3.0)\n",
            "Requirement already satisfied: charset-normalizer in /usr/local/lib/python3.12/dist-packages (from reportlab) (3.4.4)\n",
            "Downloading reportlab-4.4.5-py3-none-any.whl (2.0 MB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/2.0 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/2.0 MB\u001b[0m \u001b[31m32.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m37.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: reportlab\n",
            "Successfully installed reportlab-4.4.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fe4ef446",
        "outputId": "1e8d2658-96a5-4347-993a-f0c1a72f7fec"
      },
      "source": [
        "from reportlab.lib.pagesizes import letter\n",
        "from reportlab.platypus import SimpleDocTemplate, Paragraph, Spacer\n",
        "from reportlab.lib.styles import getSampleStyleSheet\n",
        "\n",
        "REPORT_TEXT = \"\"\"\n",
        "# Data Science Project Report\n",
        "## Trader Sentiment Analysis\n",
        "\n",
        "### Introduction\n",
        "This project analyzes trader sentiment and its relationship with market performance using historical data and sentiment scores.\n",
        "\n",
        "### Data\n",
        "- Fear Grid Index\n",
        "- Historical trading data\n",
        "- Sentiment datasets\n",
        "\n",
        "### Methodology\n",
        "- Data cleaning and aggregation\n",
        "- Sentiment analysis\n",
        "- Statistical tests (t-tests, KPI summaries)\n",
        "- Visualization of results\n",
        "\n",
        "### Results\n",
        "- CSV outputs stored in `csv_files/`\n",
        "- Charts stored in `outputs/`\n",
        "- Notebook contains full code and workflow\n",
        "\n",
        "### Conclusion\n",
        "Trader sentiment shows measurable patterns that align with market movements.\n",
        "This project demonstrates how data science can be applied to financial sentiment analysis.\n",
        "\n",
        "- Abhay Kumar Banjare\n",
        "\"\"\"\n",
        "\n",
        "def generate_pdf_report(filename, content):\n",
        "    doc = SimpleDocTemplate(filename, pagesize=letter)\n",
        "    styles = getSampleStyleSheet()\n",
        "    story = []\n",
        "\n",
        "    # Split the content into lines and format them\n",
        "    for line in content.split('\\n'):\n",
        "        if line.startswith('# '):\n",
        "            story.append(Paragraph(line.replace('# ', ''), styles['h1']))\n",
        "        elif line.startswith('## '):\n",
        "            story.append(Paragraph(line.replace('## ', ''), styles['h2']))\n",
        "        elif line.startswith('### '):\n",
        "            story.append(Paragraph(line.replace('### ', ''), styles['h3']))\n",
        "        elif line.startswith('- '):\n",
        "            story.append(Paragraph(line, styles['Normal'], bulletText='\\u2022')) # Using bullet point for list items\n",
        "        else:\n",
        "            story.append(Paragraph(line, styles['Normal']))\n",
        "        story.append(Spacer(1, 0.2 * 10))\n",
        "\n",
        "    doc.build(story)\n",
        "    print(f\"PDF report '{filename}' created successfully.\")\n",
        "\n",
        "\n",
        "output_pdf_path = \"/content/ds_abhay_kumar_banjare/ds_report.pdf\"\n",
        "generate_pdf_report(output_pdf_path, REPORT_TEXT)\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PDF report '/content/ds_abhay_kumar_banjare/ds_report.pdf' created successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gdown\n",
        "import gdown\n",
        "\n",
        "TRADER_ID = \"1IAfLZwu6rJzyWKgBToqwSmmVYU6VbjVs\"\n",
        "SENT_ID   = \"1PgQC0tO8XN-wqkNyghWc_-mnrYv_nhSf\"\n",
        "\n",
        "TRADER_RAW = f\"{CSV}/trader_data_raw.csv\"\n",
        "SENT_RAW   = f\"{CSV}/sentiment_raw.csv\"\n",
        "\n",
        "gdown.download(id=TRADER_ID, output=TRADER_RAW, quiet=False)\n",
        "gdown.download(id=SENT_ID, output=SENT_RAW, quiet=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 413
        },
        "id": "wlpzOZolKlIU",
        "outputId": "7608dbb1-797b-4d4f-926c-3b5f60a11e70"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gdown in /usr/local/lib/python3.12/dist-packages (5.2.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.12/dist-packages (from gdown) (4.13.5)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from gdown) (3.20.0)\n",
            "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.12/dist-packages (from gdown) (2.32.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from gdown) (4.67.1)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4->gdown) (2.8)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4->gdown) (4.15.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests[socks]->gdown) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests[socks]->gdown) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests[socks]->gdown) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests[socks]->gdown) (2025.11.12)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.12/dist-packages (from requests[socks]->gdown) (1.7.1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1IAfLZwu6rJzyWKgBToqwSmmVYU6VbjVs\n",
            "To: /content/ds_abhay_kumar_banjare/csv_files/trader_data_raw.csv\n",
            "100%|██████████| 47.5M/47.5M [00:01<00:00, 44.4MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1PgQC0tO8XN-wqkNyghWc_-mnrYv_nhSf\n",
            "To: /content/ds_abhay_kumar_banjare/csv_files/sentiment_raw.csv\n",
            "100%|██████████| 90.8k/90.8k [00:00<00:00, 2.74MB/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'ds_abhay_kumar_banjare/csv_files/sentiment_raw.csv'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "trader = pd.read_csv(TRADER_RAW)\n",
        "sent   = pd.read_csv(SENT_RAW)\n",
        "\n",
        "sent = sent.rename(columns={'date':'Date','classification':'Classification'})\n",
        "trader = trader.rename(columns={\n",
        "    'Execution Price':'execution_price',\n",
        "    'Size Tokens':'size',\n",
        "    'Start Position':'start_position',\n",
        "    'Closed PnL':'closedPnL'\n",
        "})\n",
        "\n",
        "trader['leverage'] = 1.0\n",
        "\n",
        "print(\"Trader DataFrame columns:\", trader.columns)\n",
        "\n",
        "trader['time'] = pd.to_datetime(trader['Timestamp IST'], errors='coerce') # Corrected: using 'Timestamp IST' column\n",
        "trader['date'] = trader['time'].dt.date\n",
        "sent['Date']   = pd.to_datetime(sent['Date']).dt.date\n",
        "\n",
        "sent['Classification'] = sent['Classification'].astype(str).str.strip().str.title()\n",
        "\n",
        "TRADER_CLEAN = f\"{CSV}/trader_data_clean.csv\"\n",
        "trader.to_csv(TRADER_CLEAN, index=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aRgF_gCeK21H",
        "outputId": "5de2f764-435c-4184-a620-4f272799fe28"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trader DataFrame columns: Index(['Account', 'Coin', 'execution_price', 'size', 'Size USD', 'Side',\n",
            "       'Timestamp IST', 'start_position', 'Direction', 'closedPnL',\n",
            "       'Transaction Hash', 'Order ID', 'Crossed', 'Fee', 'Trade ID',\n",
            "       'Timestamp', 'leverage'],\n",
            "      dtype='object')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trader['notional'] = trader['execution_price'] * trader['size']\n",
        "trader['risk_exposure'] = trader['leverage'] * trader['notional']\n",
        "trader['pnl_rate'] = np.where(trader['notional']>0,\n",
        "                              trader['closedPnL']/trader['notional'], np.nan)\n",
        "\n",
        "daily = trader.groupby('date').agg(\n",
        "    total_trades=('Account','count'),\n",
        "    total_notional=('notional','sum'),\n",
        "    avg_leverage=('leverage','mean'),\n",
        "    total_pnl=('closedPnL','sum'),\n",
        "    avg_pnl=('closedPnL','mean'),\n",
        "    avg_pnl_rate=('pnl_rate','mean')\n",
        ").reset_index()\n",
        "\n",
        "DAILY_METRICS = f\"{CSV}/agg_daily_metrics.csv\"\n",
        "daily.to_csv(DAILY_METRICS, index=False)"
      ],
      "metadata": {
        "id": "1kqa-v5vLXsU"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "merged = pd.merge(\n",
        "    daily.rename(columns={'date':'Date'}),\n",
        "    sent[['Date','Classification']],\n",
        "    on='Date',\n",
        "    how='left'\n",
        ")\n",
        "\n",
        "DAILY_SENT = f\"{CSV}/daily_with_sentiment.csv\"\n",
        "merged.to_csv(DAILY_SENT, index=False)\n"
      ],
      "metadata": {
        "id": "x-fqrnSRL7bQ"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "sns.set(style=\"whitegrid\")\n",
        "\n",
        "def save_fig(name):\n",
        "    path = f\"{OUT}/{name}\"\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(path, dpi=140)\n",
        "    plt.close()\n",
        "    print(\"Saved:\", path)\n",
        "\n",
        "# PnL by sentiment\n",
        "plt.figure(figsize=(8,6))\n",
        "sns.boxplot(data=merged.dropna(subset=['Classification']), x='Classification', y='total_pnl')\n",
        "plt.title(\"PnL by Sentiment\")\n",
        "save_fig(\"pnl_by_sentiment.png\")\n",
        "\n",
        "# Leverage over time\n",
        "plt.figure(figsize=(10,6))\n",
        "sns.lineplot(data=merged.sort_values('Date'), x='Date', y='avg_leverage')\n",
        "plt.title(\"Leverage Over Time\")\n",
        "save_fig(\"leverage_over_time.png\")\n",
        "\n",
        "# Notional by sentiment\n",
        "plt.figure(figsize=(8,6))\n",
        "sns.boxplot(data=merged.dropna(subset=['Classification']), x='Classification', y='total_notional')\n",
        "plt.title(\"Notional by Sentiment\")\n",
        "save_fig(\"notional_by_sentiment.png\")"
      ],
      "metadata": {
        "id": "NXhfMJaWL_-p",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8a0f04ac-7bbf-4c00-f642-841ad9d04dc2"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved: ds_abhay_kumar_banjare/outputs/pnl_by_sentiment.png\n",
            "Saved: ds_abhay_kumar_banjare/outputs/leverage_over_time.png\n",
            "Saved: ds_abhay_kumar_banjare/outputs/notional_by_sentiment.png\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy import stats\n",
        "\n",
        "def ttest_metric(metric):\n",
        "    df = merged.dropna(subset=[metric,'Classification'])\n",
        "    fear  = df.loc[df['Classification']=='Fear', metric]\n",
        "    greed = df.loc[df['Classification']=='Greed', metric]\n",
        "    t, p = stats.ttest_ind(greed, fear, equal_var=False, nan_policy='omit')\n",
        "    return {'metric':metric,\n",
        "            'mean_greed':float(np.nanmean(greed)),\n",
        "            'mean_fear':float(np.nanmean(fear)),\n",
        "            't_stat':float(t),\n",
        "            'p_val':float(p)}\n",
        "\n",
        "results = []\n",
        "for m in ['total_pnl','avg_leverage','total_notional','avg_pnl_rate']:\n",
        "    results.append(ttest_metric(m))\n",
        "\n",
        "ttests = pd.DataFrame(results)\n",
        "TTESTS_PATH = f\"{CSV}/ttests_alignment.csv\"\n",
        "ttests.to_csv(TTESTS_PATH, index=False)\n"
      ],
      "metadata": {
        "id": "xGOKFZYuMzuB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a64bf4cb-3047-4318-db42-a3933585c5fa"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/scipy/stats/_axis_nan_policy.py:579: RuntimeWarning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n",
            "  res = hypotest_fun_out(*samples, **kwds)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sent_map = sent.set_index('Date')['Classification']\n",
        "\n",
        "trader_processed = trader.copy()\n",
        "\n",
        "trader_processed['Classification'] = trader_processed['date'].map(sent_map)\n",
        "trader_processed['sent_code'] = trader_processed['Classification'].map({'Greed':1,'Fear':-1})\n",
        "\n",
        "trader_processed['notional'] = trader_processed['execution_price'] * trader_processed['size']\n",
        "trader_processed['risk_exposure'] = trader_processed['leverage'] * trader_processed['notional']\n",
        "trader_processed['pnl_rate'] = np.where(trader_processed['notional']>0,\n",
        "                              trader_processed['closedPnL']/trader_processed['notional'], np.nan)\n",
        "\n",
        "trader_processed = trader_processed.dropna(subset=['Direction','sent_code'])\n",
        "trader_processed['aligned'] = (trader_processed['Direction'] == trader_processed['sent_code']).astype(int)\n",
        "\n",
        "aligned_perf = trader_processed.groupby('aligned').agg(\n",
        "    trades=('Account','count'),\n",
        "    total_pnl=('closedPnL','sum'),\n",
        "    avg_pnl=('closedPnL','mean'),\n",
        "    avg_pnl_rate=('pnl_rate','mean')\n",
        ").reset_index()\n",
        "\n",
        "ALIGNED_PATH = f\"{CSV}/aligned_vs_contrarian.csv\"\n",
        "aligned_perf.to_csv(ALIGNED_PATH, index=False)\n",
        "\n",
        "# Chart\n",
        "plt.figure(figsize=(8,6))\n",
        "sns.barplot(data=aligned_perf, x='aligned', y='avg_pnl_rate')\n",
        "plt.xticks([0,1], ['Contrarian','Aligned'])\n",
        "plt.title(\"Contrarian vs Aligned PnL Rate\")\n",
        "save_fig(\"contrarian_vs_aligned_pnlrate.png\")"
      ],
      "metadata": {
        "id": "m6xkr5qpM5FO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "75ffab6d-851b-4fea-f521-1df24a188134"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved: ds_abhay_kumar_banjare/outputs/contrarian_vs_aligned_pnlrate.png\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "summary = {\n",
        "    'Greed_days': int((merged['Classification']=='Greed').sum()),\n",
        "    'Fear_days': int((merged['Classification']=='Fear').sum()),\n",
        "    'Avg_total_pnl_Greed': float(merged.loc[merged['Classification']=='Greed','total_pnl'].mean()),\n",
        "    'Avg_total_pnl_Fear': float(merged.loc[merged['Classification']=='Fear','total_pnl'].mean()),\n",
        "    'Avg_leverage_Greed': float(merged.loc[merged['Classification']=='Greed','avg_leverage'].mean()),\n",
        "    'Avg_leverage_Fear': float(merged.loc[merged['Classification']=='Fear','avg_leverage'].mean())\n",
        "}\n",
        "summary_df = pd.DataFrame([summary])\n",
        "SUMMARY_PATH = f\"{CSV}/summary_kpis.csv\"\n",
        "summary_df.to_csv(SUMMARY_PATH, index=False)\n"
      ],
      "metadata": {
        "id": "YKpYFnqlN4-e"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1db64013"
      },
      "source": [
        "# Task\n",
        "To update `README.md` with the new project structure and usage details, first read the existing content, then append the new information, and finally write the complete content back to `README.md`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "09335c05"
      },
      "source": [
        "## Append to README.md\n",
        "\n",
        "### Subtask:\n",
        "Read the current content of `README.md`, append the new project structure and usage details, and then write the updated content back to the `README.md` file.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "19ad0e8c"
      },
      "source": [
        "**Reasoning**:\n",
        "I need to define the content to be appended to the `README.md` file, including details about the project structure and generated files. This content will be stored in a string variable.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c934c494",
        "outputId": "4166e1e7-b5b3-4b61-de28-c3e2a38b6a5b"
      },
      "source": [
        "readme_content_to_add = \"\"\"\n",
        "## Project Structure\n",
        "\n",
        "- `ds_abhay_kumar_banjare/`: The root directory for the project.\n",
        "    - `csv_files/`: Contains all CSV data files.\n",
        "        - `trader_data_raw.csv`: Raw trader data downloaded from Google Drive.\n",
        "        - `sentiment_raw.csv`: Raw sentiment data downloaded from Google Drive.\n",
        "        - `trader_data_clean.csv`: Cleaned and preprocessed trader data.\n",
        "        - `agg_daily_metrics.csv`: Daily aggregated trading metrics.\n",
        "        - `daily_with_sentiment.csv`: Daily metrics merged with sentiment data.\n",
        "        - `ttests_alignment.csv`: Results of t-tests for sentiment alignment.\n",
        "        - `aligned_vs_contrarian.csv`: Performance metrics for aligned vs. contrarian trades.\n",
        "        - `summary_kpis.csv`: Key Performance Indicators summary by sentiment.\n",
        "    - `outputs/`: Stores all generated plots and figures.\n",
        "        - `pnl_by_sentiment.png`: Box plot of PnL by sentiment.\n",
        "        - `leverage_over_time.png`: Line plot of average leverage over time.\n",
        "        - `notional_by_sentiment.png`: Box plot of notional by sentiment.\n",
        "        - `contrarian_vs_aligned_pnlrate.png`: Bar plot comparing PnL rates for contrarian vs. aligned trades.\n",
        "    - `ds_report.pdf`: A PDF report summarizing the project.\n",
        "\n",
        "## Usage\n",
        "\n",
        "This project analyzes trader sentiment using historical data. The Jupyter Notebook (`.ipynb` file) contains the full workflow, including data loading, cleaning, analysis, visualization, and report generation.\n",
        "\n",
        "To run the project:\n",
        "1. Ensure you have Python and Jupyter installed.\n",
        "2. Install the required libraries (`pandas`, `numpy`, `matplotlib`, `seaborn`, `scipy`, `reportlab`, `gdown`).\n",
        "3. Execute the cells in the Jupyter Notebook sequentially.\n",
        "4. The raw data will be downloaded, processed, and analysis results (CSV files and plots) will be saved in the respective `csv_files/` and `outputs/` directories.\n",
        "\"\"\"\n",
        "\n",
        "print(\"Defined the content to be added to README.md.\")"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Defined the content to be added to README.md.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6463ec47"
      },
      "source": [
        "**Reasoning**:\n",
        "Now that the new content for `README.md` is defined, I will read the existing `README.md` file. If it doesn't exist, I'll start with an empty string to ensure I don't get an error, then append the new content, and finally write the combined content back to the `README.md` file in the root directory.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6a782fdb",
        "outputId": "69307771-31d5-4361-be8b-65ffc720bdea"
      },
      "source": [
        "readme_path = f\"{ROOT}/README.md\"\n",
        "\n",
        "try:\n",
        "    with open(readme_path, 'r') as f:\n",
        "        existing_readme_content = f.read()\n",
        "except FileNotFoundError:\n",
        "    existing_readme_content = \"# Data Science Project Report\\n\"\n",
        "\n",
        "full_readme_content = existing_readme_content + readme_content_to_add\n",
        "\n",
        "with open(readme_path, 'w') as f:\n",
        "    f.write(full_readme_content)\n",
        "\n",
        "print(f\"Successfully updated {readme_path}\")"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successfully updated ds_abhay_kumar_banjare/README.md\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "59e99490"
      },
      "source": [
        "## Final Task\n",
        "\n",
        "### Subtask:\n",
        "Confirm that the `README.md` file has been updated successfully with the new information.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f9bb7ea6"
      },
      "source": [
        "## Summary:\n",
        "\n",
        "### Q&A\n",
        "*   **Was the `README.md` file updated successfully with the new information?**\n",
        "    Yes, the `README.md` file in the project's root directory (`ds_abhay_kumar_banjare/README.md`) has been successfully updated with the specified project structure and usage details.\n",
        "\n",
        "### Data Analysis Key Findings\n",
        "*   A comprehensive block of text containing detailed project structure and usage instructions was prepared for inclusion in `README.md`.\n",
        "*   The existing content of `README.md` was retrieved; if the file was not found, a default title was used as a starting point.\n",
        "*   The newly prepared content was successfully appended to the existing `README.md` content.\n",
        "*   The combined, updated content was written back to the `README.md` file at `ds_abhay_kumar_banjare/README.md`.\n",
        "\n",
        "### Insights or Next Steps\n",
        "*   The updated `README.md` now provides clear documentation for anyone wanting to understand or replicate the project, detailing file organization and execution steps.\n",
        "*   The next step could involve manually reviewing the updated `README.md` file to ensure formatting and content accuracy for optimal readability.\n"
      ]
    }
  ]
}